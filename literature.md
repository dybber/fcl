Related work on low-level intermediate languages
================================================

Additional references can be found here:
http://wiki.portal.chalmers.se/cse/pmwiki.php/FP/PapersRelatedToFeldsparObsidianIntermediateRepresentationsAndTheLike


Low-level
---------

### Insieme / INSPIRE
<http://www.dps.uibk.ac.at/insieme/architecture.html>

### Obsidian

### OKL
"OKL: A Unified Language for Parallel Architectures" by David Medina - <http://dsmedina.com/pdf/papers/phd.pdf>

### PIRE
Intermediate representation for Feldspar, Master thesis by Ivar LÃ¥ng
<http://publications.lib.chalmers.se/records/fulltext/184387/184387.pdf>

### Intermediate representation for heterogeneous multi-core: A survey
<http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=7050496&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D7050496>

We don't have access to this paper, but it seems very relevant. From
the abstract:

    "This article studies the most popular IR techniques for
    heterogeneous multi-core, classifies them into three broad
    categories and performs a comparison among them based on the data
    structure used and their importance in academia and research"

And a lot of papers that it references also seem relevant to look at:

 * "Automatic extraction of functional parallelism from ordinary programs"
   (also not available from Chalmers)
 
 * "A Heterogeneous Parallel Framework for Domain-Specific Languages" (about Delite)
   <https://ppl.stanford.edu/papers/pact11-brown.pdf>
   <https://stanford-ppl.github.io/Delite/publications.html>

 * "Kimble: a Hierarchical Intermediate Representation for Multi-Grain Parallelism"
   <http://nbenoit.tuxfamily.org/projects/gomet/wir11-kimble.pdf>

 * and more ...

Parallel cost-model papers
--------------------------
<http://arxiv.org/pdf/1306.5076.pdf>

 * "A Practical Hierarchical Model of Parallel Computation" by Heywood and Ranka (Hierarchical PRAM)
 * "Simple Memory Machine Models for GPUs" by Koji Nakano
 * "The Hierarchical Memory Machine Model for GPUs" by Koji Nakano
 * "A detailed GPU cache model based on Reuse Distance Theory" by Nugteren et al.
 * [Modeling parallel computers as memory hierarchies](http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=315548&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D315548)
 * [LogP: A practical model of parallel computation](http://rsim.cs.uiuc.edu/arch/qual_papers/systems/5.pdf)

High-level intermediate languages
---------------------------------

### Futhark

Futhark is intended as a intermeediate language for high-performance
domain-specific languages e.g. a Monte Carlo-simulation + Automatic
Differentiation DSL or a Financial contract valuation DSL.

The Futhark project provides a rich language with a lot of work being
done on providing high-quality automatic fusion.

Futhark is thus not low-level in the sense that you are in close
contact with the hardware, but low-level in the sence that is intended
to be generated by compilers, not written by hand.

### Single-assignment C

Many of the same things just mentioned about Futhark, can also be said
about Single-assignment C (SaC).

But in contrast to Futhark, which fusion-mechanism is built around a
lot of second-order data-parallel operators, and a restricted looping
construct, the fusion in SaC is performed on one single loop
construct, which all high-level operators are written in terms of.

### Bohrium

Bohrium is intended as a data-parallel bytecode, mainly for
interpreted languages such as Python, R or MATLAB. The idea is that
interpreters spit out bytecode instructions when they occur, and the
Bohrium runtime then buffers instructions and fuses as many as
possible before dispatching the computation in the GPU. In this way no
control-flow instructions are necessary in Bohrium bytecode, as only
the data-parallel instructions needs to be allocated. Currently only a
very limited set of instructions are implemented (e.g. no scan,
scatter or gather).

The Bohrium project targets MPI, OpenMP, CUDA and are starting doing
stuff on FPGAs.

### VCODE
The intermediate language used in NESL.

### CUDA PTX
This is what CUDA compiles to, so it might be too low-level to be
interesting, but maybe there's something to learn from it? I have
never looked at it in detail.

Intermediate languages for sequential compilers
-----------------------------------------------

### LLVM
Decompilation of LLVM IR <https://github.com/UplinkCoder/axtor> <http://compilers.cs.uni-saarland.de/publications/theses/moll_bsc.pdf>

### C-- (or Cmm, or C minus minus)

A language used as intermediate language in GHC. "C without type
declarations and pointers" + a runtime system for

"beamer-who-ya-gonna-call.pdf" and associated vimeo talk: <https://vimeo.com/69025829>
